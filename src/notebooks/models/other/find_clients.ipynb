{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(f'pd=={pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in train and test datasets\n",
    "train_transaction = pd.read_csv('/Users/oskarwallberg/desktop/kaggle-datasets/ieee-fraud-detection/train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('/Users/oskarwallberg/desktop/kaggle-datasets/ieee-fraud-detection/test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "train_identity = pd.read_csv('/Users/oskarwallberg/desktop/kaggle-datasets/ieee-fraud-detection/train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('/Users/oskarwallberg/desktop/kaggle-datasets/ieee-fraud-detection/test_identity.csv', index_col='TransactionID')\n",
    "\n",
    "test_transaction.columns = train_transaction.columns.drop(labels='isFraud')\n",
    "test_identity.columns = train_identity.columns\n",
    "\n",
    "train_transaction.shape, test_transaction.shape, train_identity.shape, test_identity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The point of this notebook\n",
    "---\n",
    "=> To group Transactions into client transaction histories. Key features for grouping are card1, addr1 and D1 however these do not partition the dataset perfectly into distinct clients. Thus some further analysis is required, such as comparing aggregated measures of known variables to other measures known to be true for a single client. \n",
    "\n",
    "Some examples:\n",
    "* Measures of clients that stay constant for each transaction of that client will have a standard deviation of 0 when aggregated, if not we know the group consists of two or more clients and must be split further. \n",
    "* Aggregated measure of clients that always increment (for example counter of client transactions) should have nunique values equal to the number of transactions in that group. If not we know the group consists of two or more clients.\n",
    "\n",
    "This is not a perfect method as the dataset contains multiple NaNs which disturb the aggregated measures. This can however be somewhat accounted for by replacing NaNs with large negative values (e.g. -999) and make it clear that a NaN values exists within that group. NaN values can also be left untouched however that can have consequences for the grouping, essentially making some groups dissapear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate train and test datasets to one full dataset\n",
    "\n",
    "train = train_transaction.merge(right=train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(right=test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "dataset = pd.concat([train, test])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels for datapoints belonging to test dataset\n",
    "dataset['isTest'] = np.r_[np.zeros(train.shape[0]), np.ones(test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['D1'] # D1: days since card was registered and opened for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TransactionDay'] = dataset['TransactionDT'] // (24*60*60) # TransactionDay: Timedelta in days since transactions began being stored for this dataset\n",
    "dataset['D1n'] = dataset['TransactionDay'] - dataset['D1'] # D1n: The day the card was registered (measured from point when this dataset was starting being collected)\n",
    "dataset['D2n'] = dataset['TransactionDay'] - dataset['D2']\n",
    "dataset['D4n'] = dataset['TransactionDay'] - dataset['D4']\n",
    "dataset['D10n'] = dataset['TransactionDay'] - dataset['D10']\n",
    "dataset['D15n'] = dataset['TransactionDay'] - dataset['D15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1097231 entries, 2987000 to 4170239\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   D1n             1089931 non-null  float64\n",
      " 1   D2n             581665 non-null   float64\n",
      " 2   D4n             851458 non-null   float64\n",
      " 3   D10n            1008664 non-null  float64\n",
      " 4   D15n            996049 non-null   float64\n",
      " 5   C13             1092483 non-null  float64\n",
      " 6   card1           1097231 non-null  int64  \n",
      " 7   addr1           965916 non-null   float64\n",
      " 8   TransactionAmt  1097231 non-null  float64\n",
      " 9   dist1           453743 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 92.1 MB\n"
     ]
    }
   ],
   "source": [
    "columns_of_interest = ['D1n', 'D2n', 'D4n', 'D10n', 'D15n', 'C13', 'card1', 'addr1', 'TransactionAmt', 'dist1']\n",
    "dataset[columns_of_interest].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1097231 entries, 2987000 to 4170239\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   D1n             1097231 non-null  float64\n",
      " 1   D2n             1097231 non-null  float64\n",
      " 2   D4n             1097231 non-null  float64\n",
      " 3   D10n            1097231 non-null  float64\n",
      " 4   D15n            1097231 non-null  float64\n",
      " 5   C13             1097231 non-null  float64\n",
      " 6   card1           1097231 non-null  int64  \n",
      " 7   addr1           1097231 non-null  float64\n",
      " 8   TransactionAmt  1097231 non-null  float64\n",
      " 9   dist1           1097231 non-null  float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 92.1 MB\n"
     ]
    }
   ],
   "source": [
    "dataset[columns_of_interest] = dataset[columns_of_interest].fillna(value=-999)\n",
    "dataset[columns_of_interest].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000    289126\n",
       "2987001     38068\n",
       "2987002     78964\n",
       "2987003    379675\n",
       "2987004     76142\n",
       "            ...  \n",
       "4170235    287460\n",
       "4170236     50451\n",
       "4170237    353330\n",
       "4170238    348860\n",
       "4170239     95476\n",
       "Name: uid, Length: 1097231, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group (client) ids\n",
    "dataset['uid'] = dataset.groupby(['card1', 'addr1', 'D1n']).ngroup()\n",
    "dataset['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rowCount feature to sum and count the number of rows in each aggregated group\n",
    "dataset['rowCount'] = np.ones(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 874654 entries, 2987002 to 4170237\n",
      "Columns: 442 entries, isFraud to rowCount\n",
      "dtypes: float64(407), int64(4), object(31)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# filter away all uid associated with a single transaction, uids with only one transaction must be a single client\n",
    "uid_counts = dataset['uid'].value_counts()\n",
    "uid_2p = uid_counts.loc[uid_counts >= 2].index # 2p meaning \"2 plus\"\n",
    "dataset_2p = dataset.loc[dataset['uid'].isin(uid_2p)].copy()\n",
    "dataset_2p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D4n_mean</th>\n",
       "      <th>D4n_std</th>\n",
       "      <th>D10n_mean</th>\n",
       "      <th>D10n_std</th>\n",
       "      <th>D15n_mean</th>\n",
       "      <th>D15n_std</th>\n",
       "      <th>TrAmt_mean</th>\n",
       "      <th>TrAmt_std</th>\n",
       "      <th>dist1_mean</th>\n",
       "      <th>dist1_std</th>\n",
       "      <th>C13_nunq</th>\n",
       "      <th>rowCount_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-299.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>-299.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>-299.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>89.494879</td>\n",
       "      <td>-662.333333</td>\n",
       "      <td>583.123772</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83.613000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-356.333333</td>\n",
       "      <td>556.565659</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>243.641814</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.966667</td>\n",
       "      <td>34.797282</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386559</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>20.506097</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386561</th>\n",
       "      <td>106.642857</td>\n",
       "      <td>77.846602</td>\n",
       "      <td>106.642857</td>\n",
       "      <td>77.846602</td>\n",
       "      <td>59.214286</td>\n",
       "      <td>0.425815</td>\n",
       "      <td>33.092857</td>\n",
       "      <td>13.877803</td>\n",
       "      <td>433.285714</td>\n",
       "      <td>606.801124</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386562</th>\n",
       "      <td>357.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>124.750000</td>\n",
       "      <td>71.658333</td>\n",
       "      <td>-240.750000</td>\n",
       "      <td>505.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386565</th>\n",
       "      <td>-385.500000</td>\n",
       "      <td>867.620021</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>52.318831</td>\n",
       "      <td>-495.500000</td>\n",
       "      <td>712.056529</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386566</th>\n",
       "      <td>348.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>348.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>348.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>189.666667</td>\n",
       "      <td>62.931179</td>\n",
       "      <td>-332.333333</td>\n",
       "      <td>577.350269</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163991 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          D4n_mean     D4n_std   D10n_mean    D10n_std   D15n_mean  D15n_std  \\\n",
       "uid                                                                            \n",
       "1      -299.666667    0.577350 -299.666667    0.577350 -299.666667  0.577350   \n",
       "9       156.000000    0.000000  156.000000    0.000000  156.000000  0.000000   \n",
       "25      339.000000    0.000000  339.000000    0.000000  339.000000  0.000000   \n",
       "28     -356.333333  556.565659  105.666667  243.641814  -35.000000  0.000000   \n",
       "32     -999.000000    0.000000 -999.000000    0.000000 -999.000000  0.000000   \n",
       "...            ...         ...         ...         ...         ...       ...   \n",
       "386559   97.000000    0.000000  111.500000   20.506097   97.000000  0.000000   \n",
       "386561  106.642857   77.846602  106.642857   77.846602   59.214286  0.425815   \n",
       "386562  357.250000    0.500000   22.250000    0.500000   22.250000  0.500000   \n",
       "386565 -385.500000  867.620021  228.000000    0.000000  223.000000  0.000000   \n",
       "386566  348.333333    0.577350  348.333333    0.577350  348.333333  0.577350   \n",
       "\n",
       "        TrAmt_mean  TrAmt_std  dist1_mean   dist1_std  C13_nunq  rowCount_sum  \n",
       "uid                                                                            \n",
       "1        79.666667  89.494879 -662.333333  583.123772         3           3.0  \n",
       "9       226.000000   0.000000 -999.000000    0.000000         1           2.0  \n",
       "25       83.613000   0.000000 -999.000000    0.000000         1           2.0  \n",
       "28       62.966667  34.797282 -999.000000    0.000000         3           3.0  \n",
       "32       75.000000   0.000000 -999.000000    0.000000         2           3.0  \n",
       "...            ...        ...         ...         ...       ...           ...  \n",
       "386559  232.470000   0.000000 -999.000000    0.000000         2           2.0  \n",
       "386561   33.092857  13.877803  433.285714  606.801124        12          14.0  \n",
       "386562  124.750000  71.658333 -240.750000  505.500000         4           4.0  \n",
       "386565   75.995000  52.318831 -495.500000  712.056529         2           2.0  \n",
       "386566  189.666667  62.931179 -332.333333  577.350269         3           3.0  \n",
       "\n",
       "[163991 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clients: pd.DataFrame = dataset_2p.groupby(['uid']).aggregate({\n",
    "    'D4n': [('D4n_mean', 'mean'),\n",
    "            ('D4n_std', 'std')],\n",
    "    'D10n': [('D10n_mean', 'mean'),\n",
    "             ('D10n_std', 'std')],\n",
    "    'D15n': [('D15n_mean', 'mean'),\n",
    "             ('D15n_std', 'std')],\n",
    "    'TransactionAmt': [('TrAmt_mean', 'mean'),\n",
    "                       ('TrAmt_std', 'std')],\n",
    "     'dist1': [('dist1_mean', 'mean'),\n",
    "               ('dist1_std', 'std')],\n",
    "     'C13': [('C13_nunq', 'nunique')],\n",
    "     'rowCount': [('rowCount_sum', 'sum')]\n",
    "})\n",
    "dataset_clients.columns = dataset_clients.columns.droplevel(level=0)\n",
    "dataset_clients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
